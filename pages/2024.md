---
layout: default
year: 2024
date: 2022-08-10
title: "ICCQ-2024: 4th International Conference on Code Quality"
permalink: /2024.html
front: /images/2024/innopolis.jpg
redirect_from:
  - /index.html
  - /src.html
header: |
  The 4th International Conference on Code Quality
breadcrumbs:
  - keynote: Keynote
  - steering: Steering&nbsp;Committee
  - pc: Program&nbsp;Committee
  - dates: Important&nbsp;Dates
  - papers: Accepted&nbsp;Papers
  - program: Agenda
  - authors: Instructions&nbsp;for&nbsp;Authors
  - partners: Partners
  - /coc.html: Code of Conduct
  - organizers: Organizers
  - registration: Registration
  - /principles.html: Principles
---

Sat 22 June 2024
<br/>
Innopolis University, Russia

It's a hybrid event, all speakers are welcome to either attend it 
in person or present their work remotely over [Zoom](https://zoom.us/).
{: .warning}

The 4th **I**nternational **C**onference on **C**ode **Q**uality (ICCQ)
is a one-day computer science event
focused on
static and dynamic analysis,
program verification,
programming languages design,
software bug detection,
and software maintenance.
ICCQ is organized in cooperation with
[IEEE Computer Society](https://conferences.ieee.org/conferences_events/conferences/conferencedetails/60895).

[![ieee](/images/ieee-cs.svg)](https://conferences.ieee.org/conferences_events/conferences/conferencedetails/60895)
{: .nonprofit}

## Keynote

![xin xia](/images/pc/xin-xia.jpg)
[Xin Xia](https://xin-xia.github.io/)
<br/>
[SEAT Lab, Huawei, China](https://www.huawei.com)
<br/>
Prior to joining Huawei, Dr. Xia was an [ARC DECRA](https://www.arc.gov.au/funding-research/funding-schemes/discovery-program/discovery-early-career-researcher-award-decra) Fellow and an assistant professor at the Faculty of Information Technology, [Monash University](https://www.monash.edu/) (Australia). He [received](https://dl.acm.org/doi/abs/10.1145/3539814.3539821) the ACM SIGSOFT Early Career Researcher Award in 2022. He co-authored multiple papers, among others, in [TSE](https://www.computer.org/csdl/journal/ts) and [TOSEM](https://dl.acm.org/journal/tosem) journals, in [ICSE](http://www.icse-conferences.org/), [ESEC/FSE](https://www.esec-fse.org/), and [ASE](https://ase-conferences.org/) conferences.
{: .keynote}

<!--
## Steering Committee # {#steering}

To be determined...
{: .firebrick}
-->

## Program Committee # {#pc}

![anatoly shalyto](/images/pc/anatoly-shalyto.jpg)
[Anatoly Shalyto](https://en.wikipedia.org/wiki/Anatoly_Shalyto) (Chair)
<br/>
[ITMO University](https://itmo.ru/)<!--, Russia -->
{: .pc}

And in alphabetical order:
{: .clear}

![vahid alizadeh](/images/pc/vahid-alizadeh.jpg)
[Vahid Alizadeh](https://scholar.google.com/citations?user=d-eHN0oAAAAJ)
<br/>
[DePaul University](https://www.depaul.edu/)
{: .pc}

![vijay anant athavale](/images/pc/vijay-anant-athavale.jpg)
[Vijay Anant Athavale](https://scholar.google.co.in/citations?user=lx_lA2AAAAAJ)
<br/>
[Walchand Institute of Technology](https://witsolapur.org/)
{: .pc}

![elisa baniassad](/images/pc/elisa-baniassad.jpg)
[Elisa Baniassad](https://scholar.google.com/citations?user=h8vM3msAAAAJ)
<br/>
[University of British Columbia](https://www.cs.ubc.ca/)
{: .pc}

![pietro braione](/images/pc/pietro-braione.jpg)
[Pietro Braione](https://scholar.google.com/citations?user=ItCllEUAAAAJ)
<br/>
[University of Milano-Bicocca](https://en.unimib.it/)
{: .pc}

<!--
![rafael capilla](/images/pc/rafael-capilla.jpg)
[Rafael Capilla](https://scholar.google.com/citations?user=IXswbY8AAAAJ)
<br/>
[Rey Juan Carlos University](https://www.urjc.es/)
{: .pc}
-->

![stephen chang](/images/pc/stephen-chang.jpg)
[Stephen Chang](https://scholar.google.com/citations?user=RHPucBcAAAAJ)
<br/>
[UMass Boston](https://www.umb.edu)
{: .pc}

![bernhard egger](/images/pc/bernhard-egger.jpg)
[Bernhard Egger](https://scholar.google.com/citations?user=g-ZpvTIAAAAJ)
<br/>
[Seoul National University](https://cse.snu.ac.kr/en/professor/bernhard-egger)
{: .pc}

![eduardo fernandes](/images/pc/eduardo-fernandes.jpg)
[Eduardo Fernandes](https://scholar.google.com/citations?user=bPnuCiMAAAAJ)
<br/>
[University of Southern Denmark](https://portal.findresearcher.sdu.dk/en/organisations/sdu-software-engineering)
{: .pc}

![yusuke izawa](/images/pc/yusuke-izawa.jpg)
[Yusuke Izawa](https://scholar.google.com/citations?user=45daY7oAAAAJ)
<br/>
[Tokyo Institute of Technology](https://www.yuiza.org)
{: .pc}

![javier luis canovas izquierdo](/images/pc/javier-luis-canovas-izquierdo.jpg)
[Javier Luis Cánovas Izquierdo](https://scholar.google.com/citations?user=rPa45TcAAAAJ)
<br/>
[Universitat Oberta de Catalunya](https://www.uoc.edu/)
{: .pc}

![ranjit jhala](/images/pc/ranjit-jhala.jpg)
[Ranjit Jhala](https://scholar.google.com/citations?user=H3wb878AAAAJ)
<br/>
[University of California, San Diego](https://www.ucsd.edu)
<br/>
[ACM Fellow](https://www.amazon.science/latest-news/amazon-scholar-ranjit-jhala-chosen-as-acm-fellow-for-computer-science-contributions)
{: .pc}

![tetsuo kamina](/images/pc/tetsuo-kamina.jpg)
[Tetsuo Kamina](https://scholar.google.co.jp/citations?user=LE0VmjUAAAAJ)
<br/>
[Oita University](https://www.oita-u.ac.jp/lang/en/)
{: .pc}

![narges khakpour](/images/pc/narges-khakpour.jpg)
[Narges Khakpour](https://scholar.google.com/citations?user=ZwHcVu0AAAAJ)
<br/>
[Newcastle University](https://www.ncl.ac.uk/computing/)
{: .pc}

![kais klai](/images/pc/kais-klai.jpg)
[Kais Klai](https://scholar.google.com/citations?user=5Lv8XEMAAAAJ)
<br/>
[University Sorbonne Paris Nord](https://www.univ-spn.fr/)
{: .pc}

![antoine-mine](/images/pc/antoine-mine.jpg)
[Antoine Miné](https://scholar.google.com/citations?user=tpUTyc4AAAAJ)
<br/>
[Sorbonne Université](https://www-apr.lip6.fr/~mine/)
{: .pc}

![mkaouer mohamed](/images/pc/mkaouer-mohamed.jpg)
[Mohamed Wiem Mkaouer](https://scholar.google.com/citations?user=UoHgCukAAAAJ)
<br/>
[Rochester Institute of Technology](https://www.rit.edu/directory/mwmvse-mohamed-wiem-mkaouer)
{: .pc}

![magnus myreen](/images/pc/magnus-myreen.jpg)
[Magnus Myreen](https://scholar.google.com/citations?user=XfqNgKwAAAAJ)
<br/>
[Chalmers University of Technology](https://www.chalmers.se/en/)
{: .pc}

![francis palma](/images/pc/francis-palma.jpg?1)
[Francis Palma](https://francis-palma.net/)
<br/>
[University of New Brunswick](https://www.unb.ca/)
{: .pc}

![henrique rebelo](/images/pc/henrique-rebelo.jpg)
[Henrique Rebêlo](https://www.cin.ufpe.br/~hemr/)
<br/>
[Universidade Federal de Pernambuco](https://www.ufpe.br/)
{: .pc}

![ilya sergey](/images/pc/ilya-sergey.jpg)
[Ilya Sergey](https://ilyasergey.net/)
<br/>
[National University of Singapore](https://www.nus.edu.sg/)
{: .pc}

![yudai tanabe](/images/pc/yudai-tanabe.jpg)
[Yudai Tanabe](https://scholar.google.co.uk/citations?user=rFnRl1gAAAAJ)
<br/>
[Tokyo Institute of Technology](https://yudaitnb.github.io/pages/about)
{: .pc}

![didier verna](/images/pc/didier-verna.jpg)
[Didier Verna](https://scholar.google.fr/citations?user=O9G-pNoAAAAJ)
<br/>
[EPITA](https://www.epita.fr)
{: .pc}

![guannan wei](/images/pc/guannan-wei.jpg)
[Guannan Wei](https://scholar.google.com/citations?user=b_6L2goAAAAJ)
<br/>
[Purdue University](https://www.purdue.edu)
{: .pc}

![philip wadler](/images/pc/philip-wadler.jpg)
[Philip Wadler](https://scholar.google.com/citations?user=Iz-3VFQAAAAJ)
<br/>
[University of Edinburgh](https://www.ed.ac.uk/)
<br/>
[ACM Fellow](https://awards.acm.org/award_winners/wadler_3048733)
{: .pc}

<!--
![danning xie](/images/pc/danning-xie.jpg)
[Danning Xie](https://dnxie.github.io/)
<br/>
[Purdue University](https://www.purdue.edu/)
{: .pc}
-->

![vadim zaytsev](/images/pc/vadim-zaytsev.jpg)
[Vadim Zaytsev](https://scholar.google.com/citations?user=Ycwf7Z4AAAAJ)
<br/>
[University of Twente](https://www.utwente.nl/en/)
{: .pc}

![steve zdancewic](/images/pc/steve-zdancewic.jpg)
[Steve Zdancewic](https://scholar.google.com/citations?user=19kNRU0AAAAJ&hl=en)
<br/>
[University of Pennsylvania](https://www.upenn.edu/)
{: .pc}

<!-- 
We are forming the PC right now. If you are interested in joining, please [email us](mailto:pc@iccq.ru).
{: .firebrick .clear}
-->

## Important Dates # {#dates}

Paper/abstract submission:<br>
<del>18 Feb</del> 3 Mar 2024
([anywhere on Earth](https://en.wikipedia.org/wiki/Anywhere_on_Earth))

Author notification:<br>
<del>1 May 2024</del> 5 May 2024

Camera-ready submissions:<br>
25 May 2024

Conference:<br>
22 Jun 2024

## Program / Agenda # {#program}

Subscribe to our [YouTube channel](https://www.youtube.com/@ICCQru?sub_confirmation=1).

<!-- Watch us [live on YouTube](https://youtu.be/HtOQDYkaxgM). -->

12:00 ([Moscow time](https://en.wikipedia.org/wiki/Moscow_Time))
<!-- [![youtube icon](/images/youtube.svg#youtube "Click to watch it on YouTube")](https://www.youtube.com/watch?v=65baOBHeVMI) -->
<!-- [![ical icon](/images/ical.svg#ical "Click to add it to your Google Calendar")](http://www.google.com/calendar/event?action=TEMPLATE&dates=20230422T140000Z/20230422T141000Z&sprop=website:https://youtu.be/HtOQDYkaxgM&text=ICCQ-2023%20Opening%20Speech%20by%20Yegor%20Bugayenko&location=YouTube%20Live&details=Watch%20ICCQ%20Live:%20https://youtu.be/HtOQDYkaxgM) -->
<br/>
[Yegor Bugayenko](https://www.yegor256.com/about-me.html):
Opening
{: .agenda .agenda-10 .agenda-welcome}

12:10
<!-- [![youtube icon](/images/youtube.svg#youtube "Click to watch it on YouTube")](https://www.youtube.com/watch?v=elWFhjskVBo) -->
<!-- [![ical icon](/images/ical.svg#ical "Click to add it to your Google Calendar")](http://www.google.com/calendar/event?action=TEMPLATE&dates=20230422T142000Z/20230422T150500Z&sprop=website:https://youtu.be/HtOQDYkaxgM&text=ICCQ-2023%20Keynote%20Speech%20by%20David%20West&location=YouTube%20Live&details=Watch%20ICCQ%20Live:%20https://youtu.be/HtOQDYkaxgM) -->
<br/>
[Xin Xia](https://xin-xia.github.io/):
Keynote
{: .agenda .agenda-45 .agenda-keynote}

12:40
<!-- [![youtube icon](/images/youtube.svg#youtube "Click to watch it on YouTube")](https://www.youtube.com/watch?v=86TPTFavdFU) -->
<!-- [![ical icon](/images/ical.svg#ical "Click to add it to your Google Calendar")](http://www.google.com/calendar/event?action=TEMPLATE&dates=20230422T150500Z/20230422T153500Z&sprop=website:https://youtu.be/HtOQDYkaxgM&text=ICCQ-2023%20Rowland%20Pitts&location=YouTube%20Live&details=Watch%20ICCQ%20Live:%20https://youtu.be/HtOQDYkaxgM) -->
<br/>
[Nikolai Kudasov](https://scholar.google.com/citations?user=s6fwk54AAAAJ):<br/>
Free Foil: Generating Efficient and Scope-Safe Abstract Syntax
{: .agenda .agenda-30 .agenda-regular}

13:00
<!-- [![youtube icon](/images/youtube.svg#youtube "Click to watch it on YouTube")](https://www.youtube.com/watch?v=BC60_EGiYaE) -->
<!-- [![ical icon](/images/ical.svg#ical "Click to add it to your Google Calendar")](http://www.google.com/calendar/event?action=TEMPLATE&dates=20230422T153500Z/20230422T160500Z&sprop=website:https://youtu.be/HtOQDYkaxgM&text=ICCQ-2023%20Deema%20Alshoaibi&location=YouTube%20Live&details=Watch%20ICCQ%20Live:%20https://youtu.be/HtOQDYkaxgM) -->
<br/>
Isabel Sampaio:<br/>
Replication of a Study about the Impact of Method Chaining and Comments on Readability and Comprehension
{: .agenda .agenda-30 .agenda-regular}

13:20
<!-- [![youtube icon](/images/youtube.svg#youtube "Click to watch it on YouTube")](https://www.youtube.com/watch?v=pnXBlBNR-nY) -->
<!-- [![ical icon](/images/ical.svg#ical "Click to add it to your Google Calendar")](http://www.google.com/calendar/event?action=TEMPLATE&dates=20230422T160500Z/20230422T163500Z&sprop=website:https://youtu.be/HtOQDYkaxgM&text=ICCQ-2023%20Al%20Khan&location=YouTube%20Live&details=Watch%20ICCQ%20Live:%20https://youtu.be/HtOQDYkaxgM) -->
<br/>
[Denis Neumüller](https://scholar.google.com/citations?user=EKcF4KQAAAAJ):<br/>
Exploring the Effectiveness of Abstract Syntax Tree Patterns for Algorithm Recognition
{: .agenda .agenda-30 .agenda-regular}

13:40
<!-- [![youtube icon](/images/youtube.svg#youtube "Click to watch it on YouTube")](https://www.youtube.com/watch?v=QfwTa_tYUiA) -->
<!-- [![ical icon](/images/ical.svg#ical "Click to add it to your Google Calendar")](http://www.google.com/calendar/event?action=TEMPLATE&dates=20230422T163500Z/20230422T170500Z&sprop=website:https://youtu.be/HtOQDYkaxgM&text=ICCQ-2023%20Sergey%20Kovalchuk&location=YouTube%20Live&details=Watch%20ICCQ%20Live:%20https://youtu.be/HtOQDYkaxgM) -->
<br/>
Zixian Zhang:<br/>
Assessing the Code Clone Detection Capability of Large Language Models
{: .agenda .agenda-30 .agenda-regular}

14:00
Closing
{: .agenda .agenda-15 .agenda-welcome}

<!-- All videos are in [this playlist](https://www.youtube.com/playlist?list=PLsFvzjUuF8yoMuJp5NxQOYlJqIC-wzTT9). -->

## Accepted Papers # {#papers}

We received 23 submissions.
10 papers were desk rejected.
4 papers were accepted.
Each paper received at least three reviews from PC members.

**Free Foil: Generating Efficient and Scope-Safe Abstract Syntax**
<!-- [![youtube icon](/images/youtube.svg#youtube "Click to watch it on YouTube")](https://www.youtube.com/watch?v=QfwTa_tYUiA) -->
<!-- [![pdf icon](/images/pdf.svg#pdf "Click to read it in PDF")](https://ieeexplore.ieee.org/document/10114665) -->
[Nikolai Kudasov](https://scholar.google.com/citations?user=s6fwk54AAAAJ),
Renata Shakirova,
Egor Shalagin,
and
Karina Tyulebaeva
{: .accepted}

Handling bound identifiers correctly and efficiently is critical
in implementations of compilers, proof assistants, and theorem provers.
When choosing a representation for abstract syntax with binders,
implementors face a trade-off between type safety with intrinsic scoping,
efficiency, and generality.
The "foil" by Maclaurin, Radul, and Paszke combines
an efficient implementation of the Barendregt convention with intrinsic scoping
through advanced type system features in Haskell, such as rank-2 polymorphism
and generalized algebraic data types. Free scoped monads of Kudasov, on the other hand,
combine intrinsic scoping with de Bruijn indices as nested data types
with Sweirstra's data types à la carte approach
to allow generic implementation of algorithms
such as higher-order unification.
In this paper, we suggest two approaches of making the foil
more affordable. First, we marry free scoped monads with the foil,
allowing to generate efficient, type-safe, and generic abstract syntax representation
with binders for any language given its second-order signature.
Second, we provide Template Haskell functions that allow generating
the scope-safe representation from a naïve one under some modest assumptions.
The latter approach enables us to use existing tools like BNF Converter
to very quickly prototype complete implementation of languages,
including parsing, pretty-printing, and efficient intrinsically scoped abstract syntax.
We demonstrate both approaches using λπ with pairs and patterns
as our example object language.
Finally, we provide benchmarks comparing our implementation against the foil,
free scoped monads with nested de Bruijn indices, and some traditional implementations.
{: .abstract}

**Replication of a Study about the Impact of Method Chaining and Comments on Readability and Comprehension**
<!-- [![youtube icon](/images/youtube.svg#youtube "Click to watch it on YouTube")](https://www.youtube.com/watch?v=QfwTa_tYUiA) -->
<!-- [![pdf icon](/images/pdf.svg#pdf "Click to read it in PDF")](https://ieeexplore.ieee.org/document/10114665) -->
Isabel Sampaio
and
[Alberto Sampaio](https://scholar.google.com/citations?user=TMh0kYwAAAAJ)
{: .accepted}

It is well known that readability is an essential feature of quality code, and that many factors can affect the readability of code. This paper presents a conceptual replication of a previous experimental study that evaluated two practices associated with source code readability, namely, use of comments and method chaining. The replication study has the same research questions as the original study and involved almost all students of an OOP course of an informatics engineering program. The research process is presented, alongside decisions made and differences from the original study.
Concerning perceived readability, our study found no significant differences between method chaining variants and between comment variants. The original study did find a significant difference for comments variants. In the case
of comprehension, we found no significant differences between the method chaining variants but found a significant difference for an α = 0.1% among comments variants, both as opposed to the original study.
{: .abstract}

**Exploring the Effectiveness of Abstract Syntax Tree Patterns for Algorithm Recognition**
<!-- [![youtube icon](/images/youtube.svg#youtube "Click to watch it on YouTube")](https://www.youtube.com/watch?v=QfwTa_tYUiA) -->
<!-- [![pdf icon](/images/pdf.svg#pdf "Click to read it in PDF")](https://ieeexplore.ieee.org/document/10114665) -->
[Denis Neumüller](https://scholar.google.com/citations?user=EKcF4KQAAAAJ),
[Florian Sihler](https://scholar.google.com/citations?user=DnwmgrsAAAAJ),
Raphael Straub,
and
[Matthias Tichy](https://scholar.google.com/citations?user=hnc9E2AAAAAJ)
{: .accepted}

The automated recognition of algorithm implementations can support many software maintenance and re-engineering activities by providing knowledge about the concerns present in the code base.
Moreover, recognizing inefficient algorithms like Bubble Sort and suggesting superior alternatives from a library can help in assessing and improving the quality of a system.
Approaches from related work suffer from usability as well as scalability issues and their accuracy is not evaluated.
In this paper, we investigate how well our approach based on the abstract syntax tree of a program performs for automatic algorithm recognition.
To this end, we have implemented a prototype consisting of: A domain-specific language designed to capture the key features of an algorithm and used to express a search pattern on the abstract syntax tree,
a matching algorithm to find these features, and an initial catalog of ready to use patterns.
To create our search patterns we performed a web search using the algorithm name and described key features of the found reference implementations with our domain-specific language.
We evaluate our prototype on a subset of the BigCloneEval benchmark containing algorithms like Fibonacci, Bubble Sort, and Binary Search.
We achieve an average F1-score of 0.68 outperforming the large language model Codellama which attains 0.35.
Additionally, we use multiple code clone detection tools as a baseline for comparison, achieving a recall of 0.54 while the best-performing tool reaches 0.20.
{: .abstract}

**Assessing the Code Clone Detection Capability of Large Language Models**
<!-- [![youtube icon](/images/youtube.svg#youtube "Click to watch it on YouTube")](https://www.youtube.com/watch?v=QfwTa_tYUiA) -->
<!-- [![pdf icon](/images/pdf.svg#pdf "Click to read it in PDF")](https://ieeexplore.ieee.org/document/10114665) -->
Zixian Zhang
and
[Takfarinas Saber](https://scholar.google.com/citations?user=aevYq0oAAAAJ)
{: .accepted}

This study aims to assess the performance of two advanced Large Language Models (LLMs), GPT-3.5 and GPT-4, in the task of code clone detection. The evaluation involves testing the models on a variety of code pairs of different clone types and levels of similarity, sourced from two datasets: BigCloneBench (human-made) and GPTCloneBench (LLM-generated). Findings from the study indicate that GPT-4 consistently surpasses GPT-3.5 across all clone types. A correlation was observed between the GPTs' accuracy at identifying code clones and code similarity, with both GPT models exhibiting low effectiveness in detecting the most complex Type-4 code clones. Additionally, GPT models demonstrate a higher performance identifying code clones in LLM-generated code compared to humans-generated code. However, they do not reach impressive accuracy. These results emphasize the imperative for ongoing enhancements in LLM capabilities, particularly in the recognition of code clones and in mitigating their predisposition towards self-generated code clones—which is likely to become an issue as software engineers are more numerous to leverage LLM-enabled code generation and code refactoring tools.
{: .abstract}

## Instructions for Authors # {#authors}

[![sigplan](/images/sample-sigplan.png)](/images/sample-sigplan.pdf)
{: .sigplan}

Submissions must be in PDF, printable in black and white on
[US Letter](https://en.wikipedia.org/wiki/Letter_%28paper_size%29) sized paper.
All submissions must adhere to the
[acmart sigplan](https://www.sigplan.org/Resources/Author/)
template (two columns, 11pt font size).

In LaTeX, compile it with this formatting:

```
\documentclass[sigplan,11pt,nonacm=true,anonymous]{acmart}
\settopmatter{printfolios=false,printccs=false,printacmref=false}
\usepackage{natbib}
\begin{document}
...
\bibliographystyle{ACM-Reference-Format}
\bibliography{main}
\end{document}
```

Submitted papers must be at least 6 and at most 20 pages long,
including bibliographical references and appendices.

Submissions that do not meet the above requirements will be rejected without review.

[Click here](https://easychair.org/cfp/iccq24) to submit via EasyChair.

## Partners # {#partners}

![innopolis university](/images/partners/iu.svg)
[Innopolis University](https://innopolis.university/)
{: .partner .xxl}

![spbu](/images/partners/spbu.svg)
[St. Petersburg University](https://english.spbu.ru)
{: .partner .xxl}

![hse](/images/partners/hse.svg)
[Higher School of Economics](https://www.hse.ru/en/)
{: .partner}

<!--
Interested in joining and helping us make ICCQ even better?
[Click here](/partnership.html).
-->

## Organizers # {#organizers}

These people are making ICCQ 2024:

![yegor bugayenko](/images/orgs/yegor-bugayenko.jpg)
[Yegor<br/>Bugayenko](https://www.yegor256.com/about-me.html) (Chair)
{: .org}

![sergey belov](/images/orgs/sergey-belov.jpg)
[Sergey<br/>Belov](https://www.linkedin.com/in/sebelov/)
{: .org}

![irina grashkina](/images/orgs/irina-grashkina.jpg)
Irina<br/>Grashkina
{: .org}

![sergei prokhorov](/images/orgs/sergei-prokhorov.jpg)
[Sergei<br/>Prokhorov](https://scholar.google.ru/citations?user=sZlMj_wAAAAJ)
{: .org}

If you are interested in helping us and joining the team
of organizers, please email [team@iccq.ru](mailto:team@iccq.ru).

## Registration # {#registration}

The conference will be streamed live
on [our YouTube channel](https://www.youtube.com/channel/UC_W-pjp6HWJGjK2sayFrnag) and you
will be able to watch it without registration.
However, registration is mandatory if you want to attend the event
and enjoy a tasty lunch with some of our speakers.

Registration is free of charge.

